{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphaValues = [0.001,0.01,0.1,5,10]\n",
    "hiddenSize = 32\n",
    "#Defining a sigmoid function \n",
    "def sigmoid(x):\n",
    "    output = 1 / (1 + np.exp(-x))\n",
    "    return output\n",
    "\n",
    "    \n",
    "#derivative of sigmoid function \n",
    "# Defining a sigmoid function\n",
    "\n",
    "\n",
    "# derivative of sigmoid function\n",
    "def sigmoidDerivativeFunction(output):\n",
    "    output = output * (1 - output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some values to construct the nural net work \n",
    "#Later we will be using the actual data from the iris data set \n",
    "    \n",
    "X = np.array([[0,0,1],\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1]])\n",
    "                \n",
    "y = np.array([[0],\n",
    "\t\t\t[1],\n",
    "\t\t\t[1],\n",
    "\t\t\t[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\the current alpha value =  0.001\n",
      "Error =  0.49643992250078794\n",
      "Error =  0.49104946812904954\n",
      "Error =  0.4849763070274596\n",
      "Error =  0.4778306787926556\n",
      "Error =  0.4690384653902826\n",
      "Error =  0.458029258565275\n",
      "weight_1 [[-0.66945036  0.44057532 -0.91759208 -0.36525547 -0.76011568 -0.82926418\n",
      "  -0.61094522 -0.22947974 -0.67917735  0.15292538 -0.35220283  0.3339454\n",
      "  -0.59142231  0.67756675 -1.11442476  0.54733702 -0.31555027  0.11348483\n",
      "  -1.42577089 -0.75857317  0.67526556  0.75670996 -0.38885609  0.94740732\n",
      "   0.79895388  1.35107823 -0.82206512 -0.99660592 -0.40374837  0.75100038\n",
      "  -0.85239719 -0.11992929]\n",
      " [ 0.9583388   0.07763217  0.83646247 -0.34174625  0.57380012  0.64850887\n",
      "  -0.90837847  0.49541604  0.96767225  0.50496084 -0.51623496  0.55803271\n",
      "  -0.78484996 -0.25896594  1.37458204 -0.45776431 -0.51938006 -0.78121801\n",
      "  -1.54926221  0.42897347 -0.82710662 -0.14644147  0.00949155 -1.04761586\n",
      "  -0.17898997 -0.88967639 -0.25319071  0.77334008 -0.59686327 -0.16546404\n",
      "   0.40869142 -0.14650144]\n",
      " [-1.04683863  0.07963318  0.66801365  0.06652616  0.93839423  0.14678197\n",
      "   1.20313646 -0.70995186 -0.92113825  0.62874623 -0.29573615 -0.52831034\n",
      "   1.04482412 -0.37911984  0.85830354  0.53155125  0.86724329  0.23148292\n",
      "   0.06723081 -0.38942519 -0.59398695  0.76839252 -0.12919343  1.10968593\n",
      "   0.30301338  0.672497   -0.80031271  1.02153667  0.06853563  0.15447002\n",
      "  -0.22232653 -0.49502833]]\n",
      "weight_2 [[ 0.98938611]\n",
      " [ 0.18866442]\n",
      " [-1.05810607]\n",
      " [ 0.28955579]\n",
      " [-0.45175944]\n",
      " [ 0.07506167]\n",
      " [ 1.03264194]\n",
      " [-0.20464657]\n",
      " [ 0.98148582]\n",
      " [ 0.32310523]\n",
      " [-0.94113854]\n",
      " [ 0.82451502]\n",
      " [ 0.62413972]\n",
      " [ 1.02508842]\n",
      " [-1.09453409]\n",
      " [-0.72941822]\n",
      " [ 1.01787791]\n",
      " [ 0.49938368]\n",
      " [-1.34636059]\n",
      " [ 0.66306791]\n",
      " [ 0.74100847]\n",
      " [ 0.74366985]\n",
      " [ 0.48941783]\n",
      " [-0.99536183]\n",
      " [-0.93638148]\n",
      " [-1.22252427]\n",
      " [-0.90194915]\n",
      " [-0.70648747]\n",
      " [ 0.66498038]\n",
      " [ 0.06759568]\n",
      " [ 0.27350793]\n",
      " [ 0.7272871 ]]\n",
      "\the current alpha value =  0.01\n",
      "Error =  0.49643992250078794\n",
      "Error =  0.35637906164802124\n",
      "Error =  0.14693984546476\n",
      "Error =  0.08801561274158767\n",
      "Error =  0.06514781927504912\n",
      "Error =  0.052965808702569714\n",
      "weight_1 [[-2.43832073e+00  4.60386826e-01 -2.01731865e+00 -3.04193839e-01\n",
      "  -1.01760482e+00 -8.95344104e-01 -1.23100667e+00 -1.93076595e-01\n",
      "  -2.39779504e+00  4.59640619e-01 -1.04026630e+00  5.98257611e-01\n",
      "  -8.59036527e-01  7.90732877e-01 -3.06569583e+00  8.68107104e-01\n",
      "  -6.68450586e-01  1.42837490e-01 -3.80337709e+00 -1.28282347e+00\n",
      "   1.55574451e+00  9.04139533e-01 -4.02103990e-01  2.67679073e+00\n",
      "   1.08333513e+00  3.27051548e+00 -1.32275851e+00 -1.81496615e+00\n",
      "  -2.18276320e-01  7.20213604e-01 -1.07229877e+00 -3.24165455e-02]\n",
      " [ 2.08982983e+00  1.10629500e-01  2.51694461e+00 -3.41784146e-01\n",
      "   1.08244113e+00  5.65415920e-01 -1.42742238e+00  4.96484687e-01\n",
      "   2.01526872e+00  6.19069164e-01 -1.04442466e+00  6.73514678e-01\n",
      "  -1.05337109e+00 -1.03501971e+00  3.67163223e+00 -5.93331646e-01\n",
      "  -8.72924756e-01 -9.44060464e-01 -3.75881013e+00  7.43269593e-01\n",
      "  -2.09280104e+00  4.96432241e-01 -2.48286354e-04 -2.29546885e+00\n",
      "  -4.79084417e-01 -2.60408572e+00 -1.05996647e+00  2.08444051e+00\n",
      "  -5.74543279e-01 -1.27021185e-01  5.04031979e-01 -2.15597595e-01]\n",
      " [-1.42854714e+00  1.68655957e-01  1.25671641e+00  2.15395596e-01\n",
      "   1.01289945e+00  6.99349106e-02  2.27506957e+00 -7.11085303e-01\n",
      "  -1.38035106e+00  7.65966915e-01 -5.75057588e-01 -6.78978559e-02\n",
      "   1.68491657e+00 -6.13440443e-01  1.67258663e+00  6.21424708e-01\n",
      "   1.41210554e+00  2.75368603e-01  1.11665203e+00 -6.04878998e-01\n",
      "  -1.02739053e+00  9.25097072e-01 -1.36575878e-02  1.49426849e+00\n",
      "   3.82695444e-01  1.49679862e+00 -8.27985163e-01  1.28620392e+00\n",
      "   3.81259070e-01  1.75392595e-01 -3.25076654e-01 -3.28670228e-01]]\n",
      "weight_2 [[ 2.66096509]\n",
      " [ 0.57910777]\n",
      " [-2.31624565]\n",
      " [ 0.69614999]\n",
      " [-0.61921698]\n",
      " [ 0.38370865]\n",
      " [ 2.41768602]\n",
      " [ 0.03915781]\n",
      " [ 2.59124913]\n",
      " [ 0.89678116]\n",
      " [-1.06112574]\n",
      " [ 1.11364609]\n",
      " [ 1.66710323]\n",
      " [ 1.58182007]\n",
      " [-3.85805142]\n",
      " [-0.4732592 ]\n",
      " [ 1.84452223]\n",
      " [ 1.04122519]\n",
      " [-4.77334992]\n",
      " [ 1.26988353]\n",
      " [ 2.16733497]\n",
      " [ 1.34523229]\n",
      " [ 0.84256179]\n",
      " [-2.42618942]\n",
      " [-0.69069769]\n",
      " [-3.12866285]\n",
      " [-1.24090828]\n",
      " [-1.74872637]\n",
      " [ 1.09920224]\n",
      " [ 0.41676158]\n",
      " [ 0.77927967]\n",
      " [ 1.03150226]]\n",
      "\the current alpha value =  0.1\n",
      "Error =  0.49643992250078794\n",
      "Error =  0.030540490838555055\n",
      "Error =  0.01906387253341843\n",
      "Error =  0.014764390729581685\n",
      "Error =  0.012389242990471297\n",
      "Error =  0.010842166973777436\n",
      "weight_1 [[-3.00322215  0.46988894 -2.44991785 -0.29169761 -1.09401703 -0.9246919\n",
      "  -1.49570085 -0.19780982 -2.94732077  0.56920477 -1.20054236  0.7391777\n",
      "  -0.99690935  0.94093814 -3.62281609  0.91569534 -0.7988119   0.15271547\n",
      "  -4.33228259 -1.47490619  1.9780427   1.01855886 -0.40316011  3.16640116\n",
      "   1.14341525  3.78831657 -1.46232124 -2.14327959 -0.20790141  0.7105365\n",
      "  -1.15280043 -0.01020385]\n",
      " [ 2.55896632  0.12301871  3.01334738 -0.35452918  1.20612737  0.53836365\n",
      "  -1.67610985  0.49504917  2.47727206  0.68434391 -1.18690082  0.7721176\n",
      "  -1.1905724  -1.31975184  4.26537029 -0.61613413 -1.0057858  -0.99941692\n",
      "  -4.27416525  0.8811371  -2.58080845  0.67543441 -0.01435424 -2.70689673\n",
      "  -0.52270831 -3.10389429 -1.22829798  2.50171098 -0.59908413 -0.11270296\n",
      "   0.54708441 -0.24737497]\n",
      " [-1.56858975  0.20874264  1.40901944  0.27284564  1.02544792  0.04778983\n",
      "   2.66934814 -0.70912552 -1.52307164  0.81772844 -0.59750004  0.07534279\n",
      "   1.9235337  -0.69438737  1.9086195   0.62983806  1.63433941  0.30199459\n",
      "   1.43660642 -0.6758208  -1.18195766  0.96226455  0.034289    1.62411911\n",
      "   0.39837764  1.7065     -0.78857418  1.37036702  0.47229136  0.19277962\n",
      "  -0.35312266 -0.27019413]]\n",
      "weight_2 [[ 3.37947967]\n",
      " [ 0.69550429]\n",
      " [-2.89729689]\n",
      " [ 0.8250836 ]\n",
      " [-0.67192589]\n",
      " [ 0.48861689]\n",
      " [ 2.93206718]\n",
      " [ 0.10443291]\n",
      " [ 3.28590298]\n",
      " [ 1.08403441]\n",
      " [-1.1567535 ]\n",
      " [ 1.25764312]\n",
      " [ 2.01347533]\n",
      " [ 1.81762513]\n",
      " [-4.83373106]\n",
      " [-0.39233396]\n",
      " [ 2.13028952]\n",
      " [ 1.19801783]\n",
      " [-5.76180872]\n",
      " [ 1.47735417]\n",
      " [ 2.78210331]\n",
      " [ 1.57455136]\n",
      " [ 0.9495855 ]\n",
      " [-3.00227315]\n",
      " [-0.62055552]\n",
      " [-3.85978441]\n",
      " [-1.37326902]\n",
      " [-2.19254496]\n",
      " [ 1.24789397]\n",
      " [ 0.52616952]\n",
      " [ 0.92012025]\n",
      " [ 1.12857349]]\n",
      "\the current alpha value =  5\n",
      "Error =  0.49643992250078794\n",
      "Error =  0.0031288111022108236\n",
      "Error =  0.002148874613183779\n",
      "Error =  0.0017283934796573199\n",
      "Error =  0.0014820066652157572\n",
      "Error =  0.0013158061206984056\n",
      "weight_1 [[-4.80236027 -0.18537579 -1.49303547 -0.71406001 -1.55326439 -2.11819255\n",
      "  -0.63563205 -0.64648604 -4.86657265 -0.77163472 -1.65501673 -0.52256476\n",
      "  -0.74976116  2.23455819 -4.11774337 -0.14432112 -0.47663236  0.6530392\n",
      "  -5.46603418 -2.58938534  3.39215607  0.62521077 -0.89226574  0.88679935\n",
      "   0.04098306  3.68761411 -1.62745007 -1.86657329 -0.47997531  0.30723018\n",
      "  -1.97365923 -0.40493218]\n",
      " [ 3.73838162 -0.72979611  0.11832453 -0.73205586 -0.01889221  0.99255762\n",
      "  -1.56165124  0.0244707   3.77984956 -0.35406269 -1.64905551 -0.12535096\n",
      "  -1.25296211 -3.21800225  5.43288743 -1.10449022 -1.19633214 -1.91412231\n",
      "  -5.41187877  1.59863465 -4.56101851 -1.80418294 -0.26819111 -2.34618887\n",
      "  -0.72675004 -2.24686079 -1.430382    0.31498954 -0.94267607 -1.19878925\n",
      "   0.92585369 -0.56729456]\n",
      " [-1.93231256 -1.13748276 -0.71708081 -0.83455598 -0.54101604 -0.90119131\n",
      "   0.96050532 -1.50232755 -1.9426502  -0.90068833 -0.9364313  -1.51479171\n",
      "   0.19487188 -1.28153552  1.98513328 -0.86396809 -0.07537106 -0.648321\n",
      "   1.96362817 -1.12160628 -1.69676013 -0.6970337  -1.00501965 -0.45370285\n",
      "  -1.20791143  1.10392111 -1.15074318 -0.45961257 -0.71719018 -1.08101041\n",
      "  -0.98079982 -1.22561504]]\n",
      "weight_2 [[ 5.54139972]\n",
      " [ 0.37757636]\n",
      " [ 0.51600396]\n",
      " [ 0.25261931]\n",
      " [ 0.54703704]\n",
      " [ 1.48442099]\n",
      " [ 1.22051528]\n",
      " [ 0.19892504]\n",
      " [ 5.64582149]\n",
      " [ 0.35821797]\n",
      " [-1.26120935]\n",
      " [ 0.4388694 ]\n",
      " [ 0.5674872 ]\n",
      " [ 3.14803362]\n",
      " [-6.93290669]\n",
      " [ 0.371938  ]\n",
      " [ 0.70572059]\n",
      " [ 1.34868133]\n",
      " [-7.55694824]\n",
      " [ 2.18658326]\n",
      " [ 5.15934722]\n",
      " [ 1.29903955]\n",
      " [ 0.44274916]\n",
      " [ 1.43068738]\n",
      " [ 0.194902  ]\n",
      " [-3.42934229]\n",
      " [-1.21028953]\n",
      " [ 0.82998543]\n",
      " [ 0.44454544]\n",
      " [ 0.73273206]\n",
      " [ 1.39265634]\n",
      " [ 0.50959558]]\n",
      "\the current alpha value =  10\n",
      "Error =  0.49643992250078794\n",
      "Error =  0.002254538839644365\n",
      "Error =  0.0015372348629016657\n",
      "Error =  0.00123439543710358\n",
      "Error =  0.0010580718173873289\n",
      "Error =  0.0009395364918713383\n",
      "weight_1 [[-5.12981347 -0.39940291 -1.45711585 -1.01137359 -1.54713647 -2.27846015\n",
      "  -1.37910066  0.46489941 -5.51547069 -0.86958432 -1.70689212 -0.37598016\n",
      "  -1.63780113  2.34243791 -1.74765111 -0.66823165 -1.03655024 -0.04610745\n",
      "  -6.08389435 -2.14774122  4.27269283  2.31314256 -0.98345643 -0.02944815\n",
      "   3.23010338 -0.02498876 -1.44045683 -1.7178718  -0.94605825 -0.20835705\n",
      "  -1.79061185 -0.66237064]\n",
      " [ 3.81287314 -0.61229624 -0.81693177 -0.97346748 -0.73861315  0.76514381\n",
      "  -1.70535246  0.77095122  4.12872217 -0.57839343 -1.66805299 -0.11924695\n",
      "  -1.72569726 -3.53437928  0.06442295 -1.05719275 -1.32941766 -1.76509924\n",
      "  -6.02804247  0.73419584 -5.8015089  -3.77589313 -0.6089705  -1.96058889\n",
      "   3.27757319 -1.13108479 -1.23530421 -0.60259187 -1.11742832 -1.07248086\n",
      "   0.1893308  -0.70733363]\n",
      " [-2.02876428 -1.52714397 -1.2242008  -1.27004294 -1.15868887 -1.46223206\n",
      "  -0.74093515 -1.14475499 -2.14976064 -1.38826213 -1.01093371 -1.80202846\n",
      "  -0.71723801 -1.50885168 -1.42286911 -1.35055683 -1.04481628 -1.35325712\n",
      "   2.45541265 -1.6185515  -2.17486983 -1.36108395 -1.45263127 -1.16282022\n",
      "  -4.71861353 -1.5519827  -1.36404514 -1.15270615 -1.24094461 -1.63539506\n",
      "  -1.59283823 -1.63735076]]\n",
      "weight_2 [[ 5.19459456]\n",
      " [-0.52270727]\n",
      " [-0.5548398 ]\n",
      " [-0.52261533]\n",
      " [-0.41057647]\n",
      " [ 0.97955107]\n",
      " [-0.75008047]\n",
      " [-1.49643775]\n",
      " [ 5.85298225]\n",
      " [-0.48835558]\n",
      " [-1.44345191]\n",
      " [-0.56961184]\n",
      " [-1.03399794]\n",
      " [ 2.85558142]\n",
      " [ 0.21927148]\n",
      " [-0.43886377]\n",
      " [-0.46171907]\n",
      " [ 0.35822308]\n",
      " [-8.69592953]\n",
      " [ 0.93791255]\n",
      " [ 6.48550861]\n",
      " [ 3.01228139]\n",
      " [-0.36622479]\n",
      " [ 0.38738959]\n",
      " [-7.87413205]\n",
      " [-0.1405295 ]\n",
      " [-1.14608067]\n",
      " [-0.26314546]\n",
      " [-0.42787726]\n",
      " [-0.13914043]\n",
      " [ 0.41454431]\n",
      " [-0.2751824 ]]\n"
     ]
    }
   ],
   "source": [
    "for alpha in alphaValues:\n",
    "    print(\"\\the current alpha value = \",alpha)\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    #initializing Random weights \n",
    "    \n",
    "    weight_1 = 2*np.random.random((3,hiddenSize)) - 1\n",
    "    weight_2 = 2*np.random.random((hiddenSize,1)) - 1\n",
    "    \n",
    "    #checking the weights to see how the gradiants are changing \n",
    "    \n",
    "    weight_1_dirCount = np.zeros_like(weight_1)\n",
    "    weight_2_dirCount = np.zeros_like(weight_2)\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    prev_weight_1_update = np.zeros_like(weight_1)\n",
    "    prev_weight_2_update = np.zeros_like(weight_2)\n",
    "   \n",
    "\n",
    "   \n",
    "    for j in range(60000):\n",
    "        #Forward propogation from one layer to another i.e between layers 0 , 1, 2\n",
    "        #layer_0 = X\n",
    "        #layer_1 = sigmoid(np.dot(layer_0,weight_1))   #Here we are multiplying   ThetaTranspose* X\n",
    "        #print(type(layer_1))\n",
    "        #layer_2 = sigmoid(np.dot(layer_1,weight_2)) # the same thing with respoect to the second layer .. ie thetaTranspose*X\n",
    "        \n",
    "        \n",
    "        layer_0 = X\n",
    "        layer_1 = sigmoid(np.dot(layer_0,weight_1))\n",
    "        layer_2 = sigmoid(np.dot(layer_1,weight_2))\n",
    "        #Caliculating the error value \n",
    "        \n",
    "        ForwardPropError = y - layer_2\n",
    "        \n",
    "        if (j%10000) == 0:\n",
    "            print(\"Error = \",np.mean(np.abs(ForwardPropError)))\n",
    "                  \n",
    "        \n",
    "        ##Back propogation \n",
    "        layer2_Sigma = ForwardPropError*sigmoidDerivativeFunction(layer_2)\n",
    "        \n",
    "        layer1_Error =  layer2_Sigma.dot(weight_2.T)\n",
    "    \n",
    "        layer_1Sigma = layer1_Error*sigmoidDerivativeFunction(layer_1)\n",
    "        \n",
    "        \n",
    "                  \n",
    "                  \n",
    "    \n",
    "        #We are suggesting values .. i.e how much of it is wrong in each layer \n",
    "        #baically updating the weights withs respective to values and the errors observed \n",
    "        weight_2_Update = (layer_1.T.dot(layer2_Sigma))\n",
    "        weight_1_Update = (layer_0.T.dot(layer_1Sigma))\n",
    "        \n",
    "        #We are checking what direction the gradient is moving           \n",
    "        if(j > 0):\n",
    "                  weight_1_dirCount += np.abs(((weight_1_Update> 0)+0)-\n",
    "                                             \n",
    "                                             ((prev_weight_1_update>0)+0))\n",
    "                  weight_2_dirCount += np.abs(((weight_2_Update> 0)+0)-\n",
    "                                             \n",
    "                                             ((prev_weight_2_update>0)+0))\n",
    "        weight_1 += alpha*weight_1_Update\n",
    "        weight_2 += alpha*weight_2_Update\n",
    "                  \n",
    "                  \n",
    "                  \n",
    "        prev_weight_1_update = weight_1_Update\n",
    "        prev_weight_2_update = weight_2_Update\n",
    " \n",
    "                  \n",
    "    print(\"weight_1\",weight_1)\n",
    "    print(\"weight_2\",weight_2)\n",
    "                  \n",
    "                  \n",
    "                  \n",
    "                  \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training With Alpha:0.001\n",
      "Error:0.49641003190272537\n",
      "Error:0.49516402549338606\n",
      "Error:0.4935960431880486\n",
      "Error:0.4916063585594306\n",
      "Error:0.48910016654420474\n",
      "Error:0.48597785784615843\n",
      "Synapse 0\n",
      "[[-0.28448441  0.32471214 -1.53496167 -0.47594822]\n",
      " [-0.7550616  -1.04593014 -1.45446052 -0.32606771]\n",
      " [-0.2594825  -0.13487028 -0.29722666  0.40028038]]\n",
      "Synapse 0 Update Direction Changes\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 0. 1. 1.]]\n",
      "Synapse 1\n",
      "[[-0.61957526]\n",
      " [ 0.76414675]\n",
      " [-1.49797046]\n",
      " [ 0.40734574]]\n",
      "Synapse 1 Update Direction Changes\n",
      "[[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "\n",
      "Training With Alpha:0.01\n",
      "Error:0.49641003190272537\n",
      "Error:0.45743107444190134\n",
      "Error:0.359097202563399\n",
      "Error:0.23935813715897253\n",
      "Error:0.1430706590133703\n",
      "Error:0.09859642980892719\n",
      "Synapse 0\n",
      "[[ 2.39225985  2.56885428 -5.38289334 -3.29231397]\n",
      " [-0.35379718 -4.6509363  -5.67005693 -1.74287864]\n",
      " [-0.15431323 -1.17147894  1.97979367  3.44633281]]\n",
      "Synapse 0 Update Direction Changes\n",
      "[[1. 1. 0. 0.]\n",
      " [2. 0. 0. 2.]\n",
      " [4. 2. 1. 1.]]\n",
      "Synapse 1\n",
      "[[-3.70045078]\n",
      " [ 4.57578637]\n",
      " [-7.63362462]\n",
      " [ 4.73787613]]\n",
      "Synapse 1 Update Direction Changes\n",
      "[[2.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "\n",
      "Training With Alpha:0.1\n",
      "Error:0.49641003190272537\n",
      "Error:0.042888017000115755\n",
      "Error:0.02409899422852161\n",
      "Error:0.018110652146797843\n",
      "Error:0.014987616272210912\n",
      "Error:0.013014490538142586\n",
      "Synapse 0\n",
      "[[ 3.88035459  3.6391263  -5.99509098 -3.8224267 ]\n",
      " [-1.72462557 -5.41496387 -6.30737281 -3.03987763]\n",
      " [ 0.45953952 -1.77301389  2.37235987  5.04309824]]\n",
      "Synapse 0 Update Direction Changes\n",
      "[[1. 1. 0. 0.]\n",
      " [2. 0. 0. 2.]\n",
      " [4. 2. 1. 1.]]\n",
      "Synapse 1\n",
      "[[-5.72386389]\n",
      " [ 6.15041318]\n",
      " [-9.40272079]\n",
      " [ 6.61461026]]\n",
      "Synapse 1 Update Direction Changes\n",
      "[[2.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "\n",
      "Training With Alpha:1\n",
      "Error:0.49641003190272537\n",
      "Error:0.008584525653247159\n",
      "Error:0.0057894598625078085\n",
      "Error:0.004629176776769985\n",
      "Error:0.003958765280273649\n",
      "Error:0.0035101225678616766\n",
      "Synapse 0\n",
      "[[ 4.6013571   4.17197193 -6.30956245 -4.19745118]\n",
      " [-2.58413484 -5.81447929 -6.60793435 -3.68396123]\n",
      " [ 0.97538679 -2.02685775  2.52949751  5.84371739]]\n",
      "Synapse 0 Update Direction Changes\n",
      "[[1. 1. 0. 0.]\n",
      " [2. 0. 0. 2.]\n",
      " [4. 2. 1. 1.]]\n",
      "Synapse 1\n",
      "[[ -6.96765763]\n",
      " [  7.14101949]\n",
      " [-10.31917382]\n",
      " [  7.86128405]]\n",
      "Synapse 1 Update Direction Changes\n",
      "[[2.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "\n",
      "Training With Alpha:10\n",
      "Error:0.49641003190272537\n",
      "Error:0.003129388763011837\n",
      "Error:0.002144595579852179\n",
      "Error:0.0017239754995622308\n",
      "Error:0.0014782145122908034\n",
      "Error:0.0013127406283356764\n",
      "Synapse 0\n",
      "[[ 4.52597806  5.77663165 -7.34266481 -5.29379829]\n",
      " [ 1.66715206 -7.16447274 -7.99779235 -1.81881849]\n",
      " [-4.27032921 -3.35838279  3.44594007  4.88852208]]\n",
      "Synapse 0 Update Direction Changes\n",
      "[[ 7. 19.  2.  6.]\n",
      " [ 7.  2.  0. 22.]\n",
      " [19. 26.  9. 17.]]\n",
      "Synapse 1\n",
      "[[ -8.58485788]\n",
      " [ 10.1786297 ]\n",
      " [-14.87601886]\n",
      " [  7.57026121]]\n",
      "Synapse 1 Update Direction Changes\n",
      "[[22.]\n",
      " [15.]\n",
      " [ 4.]\n",
      " [15.]]\n",
      "\n",
      "Training With Alpha:100\n",
      "Error:0.49641003190272537\n",
      "Error:0.12547698383358538\n",
      "Error:0.12533033354043677\n",
      "Error:0.12526772879373652\n",
      "Error:0.12523107370012884\n",
      "Error:0.12520635280373757\n",
      "Synapse 0\n",
      "[[-17.20515383   1.89881344 -16.95533169  -8.23482697]\n",
      " [  5.7023927  -17.23785048  -9.48052434  -7.92972576]\n",
      " [ -4.18780303  -0.33881828   2.8202323   -8.40059859]]\n",
      "Synapse 0 Update Direction Changes\n",
      "[[ 8.  7.  3.  2.]\n",
      " [13.  8.  2.  4.]\n",
      " [16. 13. 12.  8.]]\n",
      "Synapse 1\n",
      "[[  9.68285305]\n",
      " [  9.5573212 ]\n",
      " [-16.03906837]\n",
      " [  6.27326973]]\n",
      "Synapse 1 Update Direction Changes\n",
      "[[13.]\n",
      " [11.]\n",
      " [12.]\n",
      " [10.]]\n",
      "\n",
      "Training With Alpha:1000\n",
      "Error:0.49641003190272537\n",
      "Error:0.5\n",
      "Error:0.5\n",
      "Error:0.5\n",
      "Error:0.5\n",
      "Error:0.5\n",
      "Synapse 0\n",
      "[[-56.06177241  -4.66916407  -5.65196178 -23.05868769]\n",
      " [ -4.52271708  -4.78629811 -10.887702   -15.85879101]\n",
      " [-89.56678495  10.61497652  37.02351519 -48.33299795]]\n",
      "Synapse 0 Update Direction Changes\n",
      "[[3. 2. 4. 1.]\n",
      " [1. 2. 2. 1.]\n",
      " [6. 6. 4. 1.]]\n",
      "Synapse 1\n",
      "[[  25.16188889]\n",
      " [  -8.65053733]\n",
      " [-104.60697286]\n",
      " [  11.41582458]]\n",
      "Synapse 1 Update Direction Changes\n",
      "[[7.]\n",
      " [7.]\n",
      " [7.]\n",
      " [3.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "alphas = [0.001,0.01,0.1,1,10,100,1000]\n",
    "\n",
    "# compute sigmoid nonlinearity\n",
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "# convert output of sigmoid function to its derivative\n",
    "def sigmoid_output_to_derivative(output):\n",
    "    return output*(1-output)\n",
    "    \n",
    "X = np.array([[0,0,1],\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1]])\n",
    "                \n",
    "y = np.array([[0],\n",
    "\t\t\t[1],\n",
    "\t\t\t[1],\n",
    "\t\t\t[0]])\n",
    "\n",
    "\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(\"\\nTraining With Alpha:\" + str(alpha))\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # randomly initialize our weights with mean 0\n",
    "    synapse_0 = 2*np.random.random((3,4)) - 1\n",
    "    synapse_1 = 2*np.random.random((4,1)) - 1\n",
    "        \n",
    "    prev_synapse_0_weight_update = np.zeros_like(synapse_0)\n",
    "    prev_synapse_1_weight_update = np.zeros_like(synapse_1)\n",
    "\n",
    "    synapse_0_direction_count = np.zeros_like(synapse_0)\n",
    "    synapse_1_direction_count = np.zeros_like(synapse_1)\n",
    "        \n",
    "    for j in range(60000):\n",
    "\n",
    "        # Feed forward through layers 0, 1, and 2\n",
    "        layer_0 = X\n",
    "        layer_1 = sigmoid(np.dot(layer_0,synapse_0))\n",
    "        layer_2 = sigmoid(np.dot(layer_1,synapse_1))\n",
    "\n",
    "        # how much did we miss the target value?\n",
    "        layer_2_error = y - layer_2\n",
    "\n",
    "        if (j% 10000) == 0:\n",
    "            print(\"Error:\" + str(np.mean(np.abs(layer_2_error))))\n",
    "\n",
    "        # in what direction is the target value?\n",
    "        # were we really sure? if so, don't change too much.\n",
    "        layer_2_delta = layer_2_error*sigmoid_output_to_derivative(layer_2)\n",
    "\n",
    "        # how much did each l1 value contribute to the l2 error (according to the weights)?\n",
    "        layer_1_error = layer_2_delta.dot(synapse_1.T)\n",
    "\n",
    "        # in what direction is the target l1?\n",
    "        # were we really sure? if so, don't change too much.\n",
    "        layer_1_delta = layer_1_error * sigmoid_output_to_derivative(layer_1)\n",
    "        \n",
    "        synapse_1_weight_update = (layer_1.T.dot(layer_2_delta))\n",
    "        synapse_0_weight_update = (layer_0.T.dot(layer_1_delta))\n",
    "        \n",
    "        if(j > 0):\n",
    "            synapse_0_direction_count += np.abs(((synapse_0_weight_update > 0)+0) - ((prev_synapse_0_weight_update > 0) + 0))\n",
    "            synapse_1_direction_count += np.abs(((synapse_1_weight_update > 0)+0) - ((prev_synapse_1_weight_update > 0) + 0))        \n",
    "        \n",
    "        synapse_1 += alpha * synapse_1_weight_update\n",
    "        synapse_0 += alpha * synapse_0_weight_update\n",
    "        \n",
    "        prev_synapse_0_weight_update = synapse_0_weight_update\n",
    "        prev_synapse_1_weight_update = synapse_1_weight_update\n",
    "    \n",
    "    print(\"Synapse 0\")\n",
    "    print(synapse_0)\n",
    "    \n",
    "    print(\"Synapse 0 Update Direction Changes\")\n",
    "    print(synapse_0_direction_count)\n",
    "    \n",
    "    print(\"Synapse 1\")\n",
    "    print(synapse_1)\n",
    "\n",
    "    print(\"Synapse 1 Update Direction Changes\")\n",
    "    print(synapse_1_direction_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\the current alpha value =  0.001\n",
      "Error =  0.49643992250078794\n",
      "Error =  0.49104946812904954\n",
      "Error =  0.4849763070274596\n",
      "Error =  0.4778306787926556\n",
      "Error =  0.4690384653902826\n",
      "Error =  0.458029258565275\n",
      "weight_1 [[-0.66945036  0.44057532 -0.91759208 -0.36525547 -0.76011568 -0.82926418\n",
      "  -0.61094522 -0.22947974 -0.67917735  0.15292538 -0.35220283  0.3339454\n",
      "  -0.59142231  0.67756675 -1.11442476  0.54733702 -0.31555027  0.11348483\n",
      "  -1.42577089 -0.75857317  0.67526556  0.75670996 -0.38885609  0.94740732\n",
      "   0.79895388  1.35107823 -0.82206512 -0.99660592 -0.40374837  0.75100038\n",
      "  -0.85239719 -0.11992929]\n",
      " [ 0.9583388   0.07763217  0.83646247 -0.34174625  0.57380012  0.64850887\n",
      "  -0.90837847  0.49541604  0.96767225  0.50496084 -0.51623496  0.55803271\n",
      "  -0.78484996 -0.25896594  1.37458204 -0.45776431 -0.51938006 -0.78121801\n",
      "  -1.54926221  0.42897347 -0.82710662 -0.14644147  0.00949155 -1.04761586\n",
      "  -0.17898997 -0.88967639 -0.25319071  0.77334008 -0.59686327 -0.16546404\n",
      "   0.40869142 -0.14650144]\n",
      " [-1.04683863  0.07963318  0.66801365  0.06652616  0.93839423  0.14678197\n",
      "   1.20313646 -0.70995186 -0.92113825  0.62874623 -0.29573615 -0.52831034\n",
      "   1.04482412 -0.37911984  0.85830354  0.53155125  0.86724329  0.23148292\n",
      "   0.06723081 -0.38942519 -0.59398695  0.76839252 -0.12919343  1.10968593\n",
      "   0.30301338  0.672497   -0.80031271  1.02153667  0.06853563  0.15447002\n",
      "  -0.22232653 -0.49502833]]\n",
      "weight_2 [[ 0.98938611]\n",
      " [ 0.18866442]\n",
      " [-1.05810607]\n",
      " [ 0.28955579]\n",
      " [-0.45175944]\n",
      " [ 0.07506167]\n",
      " [ 1.03264194]\n",
      " [-0.20464657]\n",
      " [ 0.98148582]\n",
      " [ 0.32310523]\n",
      " [-0.94113854]\n",
      " [ 0.82451502]\n",
      " [ 0.62413972]\n",
      " [ 1.02508842]\n",
      " [-1.09453409]\n",
      " [-0.72941822]\n",
      " [ 1.01787791]\n",
      " [ 0.49938368]\n",
      " [-1.34636059]\n",
      " [ 0.66306791]\n",
      " [ 0.74100847]\n",
      " [ 0.74366985]\n",
      " [ 0.48941783]\n",
      " [-0.99536183]\n",
      " [-0.93638148]\n",
      " [-1.22252427]\n",
      " [-0.90194915]\n",
      " [-0.70648747]\n",
      " [ 0.66498038]\n",
      " [ 0.06759568]\n",
      " [ 0.27350793]\n",
      " [ 0.7272871 ]]\n",
      "\the current alpha value =  0.01\n",
      "Error =  0.49643992250078794\n",
      "Error =  0.35637906164802124\n",
      "Error =  0.14693984546476\n",
      "Error =  0.08801561274158767\n",
      "Error =  0.06514781927504912\n",
      "Error =  0.052965808702569714\n",
      "weight_1 [[-2.43832073e+00  4.60386826e-01 -2.01731865e+00 -3.04193839e-01\n",
      "  -1.01760482e+00 -8.95344104e-01 -1.23100667e+00 -1.93076595e-01\n",
      "  -2.39779504e+00  4.59640619e-01 -1.04026630e+00  5.98257611e-01\n",
      "  -8.59036527e-01  7.90732877e-01 -3.06569583e+00  8.68107104e-01\n",
      "  -6.68450586e-01  1.42837490e-01 -3.80337709e+00 -1.28282347e+00\n",
      "   1.55574451e+00  9.04139533e-01 -4.02103990e-01  2.67679073e+00\n",
      "   1.08333513e+00  3.27051548e+00 -1.32275851e+00 -1.81496615e+00\n",
      "  -2.18276320e-01  7.20213604e-01 -1.07229877e+00 -3.24165455e-02]\n",
      " [ 2.08982983e+00  1.10629500e-01  2.51694461e+00 -3.41784146e-01\n",
      "   1.08244113e+00  5.65415920e-01 -1.42742238e+00  4.96484687e-01\n",
      "   2.01526872e+00  6.19069164e-01 -1.04442466e+00  6.73514678e-01\n",
      "  -1.05337109e+00 -1.03501971e+00  3.67163223e+00 -5.93331646e-01\n",
      "  -8.72924756e-01 -9.44060464e-01 -3.75881013e+00  7.43269593e-01\n",
      "  -2.09280104e+00  4.96432241e-01 -2.48286354e-04 -2.29546885e+00\n",
      "  -4.79084417e-01 -2.60408572e+00 -1.05996647e+00  2.08444051e+00\n",
      "  -5.74543279e-01 -1.27021185e-01  5.04031979e-01 -2.15597595e-01]\n",
      " [-1.42854714e+00  1.68655957e-01  1.25671641e+00  2.15395596e-01\n",
      "   1.01289945e+00  6.99349106e-02  2.27506957e+00 -7.11085303e-01\n",
      "  -1.38035106e+00  7.65966915e-01 -5.75057588e-01 -6.78978559e-02\n",
      "   1.68491657e+00 -6.13440443e-01  1.67258663e+00  6.21424708e-01\n",
      "   1.41210554e+00  2.75368603e-01  1.11665203e+00 -6.04878998e-01\n",
      "  -1.02739053e+00  9.25097072e-01 -1.36575878e-02  1.49426849e+00\n",
      "   3.82695444e-01  1.49679862e+00 -8.27985163e-01  1.28620392e+00\n",
      "   3.81259070e-01  1.75392595e-01 -3.25076654e-01 -3.28670228e-01]]\n",
      "weight_2 [[ 2.66096509]\n",
      " [ 0.57910777]\n",
      " [-2.31624565]\n",
      " [ 0.69614999]\n",
      " [-0.61921698]\n",
      " [ 0.38370865]\n",
      " [ 2.41768602]\n",
      " [ 0.03915781]\n",
      " [ 2.59124913]\n",
      " [ 0.89678116]\n",
      " [-1.06112574]\n",
      " [ 1.11364609]\n",
      " [ 1.66710323]\n",
      " [ 1.58182007]\n",
      " [-3.85805142]\n",
      " [-0.4732592 ]\n",
      " [ 1.84452223]\n",
      " [ 1.04122519]\n",
      " [-4.77334992]\n",
      " [ 1.26988353]\n",
      " [ 2.16733497]\n",
      " [ 1.34523229]\n",
      " [ 0.84256179]\n",
      " [-2.42618942]\n",
      " [-0.69069769]\n",
      " [-3.12866285]\n",
      " [-1.24090828]\n",
      " [-1.74872637]\n",
      " [ 1.09920224]\n",
      " [ 0.41676158]\n",
      " [ 0.77927967]\n",
      " [ 1.03150226]]\n",
      "\the current alpha value =  0.1\n",
      "Error =  0.49643992250078794\n",
      "Error =  0.030540490838555055\n",
      "Error =  0.01906387253341843\n",
      "Error =  0.014764390729581685\n",
      "Error =  0.012389242990471297\n",
      "Error =  0.010842166973777436\n",
      "weight_1 [[-3.00322215  0.46988894 -2.44991785 -0.29169761 -1.09401703 -0.9246919\n",
      "  -1.49570085 -0.19780982 -2.94732077  0.56920477 -1.20054236  0.7391777\n",
      "  -0.99690935  0.94093814 -3.62281609  0.91569534 -0.7988119   0.15271547\n",
      "  -4.33228259 -1.47490619  1.9780427   1.01855886 -0.40316011  3.16640116\n",
      "   1.14341525  3.78831657 -1.46232124 -2.14327959 -0.20790141  0.7105365\n",
      "  -1.15280043 -0.01020385]\n",
      " [ 2.55896632  0.12301871  3.01334738 -0.35452918  1.20612737  0.53836365\n",
      "  -1.67610985  0.49504917  2.47727206  0.68434391 -1.18690082  0.7721176\n",
      "  -1.1905724  -1.31975184  4.26537029 -0.61613413 -1.0057858  -0.99941692\n",
      "  -4.27416525  0.8811371  -2.58080845  0.67543441 -0.01435424 -2.70689673\n",
      "  -0.52270831 -3.10389429 -1.22829798  2.50171098 -0.59908413 -0.11270296\n",
      "   0.54708441 -0.24737497]\n",
      " [-1.56858975  0.20874264  1.40901944  0.27284564  1.02544792  0.04778983\n",
      "   2.66934814 -0.70912552 -1.52307164  0.81772844 -0.59750004  0.07534279\n",
      "   1.9235337  -0.69438737  1.9086195   0.62983806  1.63433941  0.30199459\n",
      "   1.43660642 -0.6758208  -1.18195766  0.96226455  0.034289    1.62411911\n",
      "   0.39837764  1.7065     -0.78857418  1.37036702  0.47229136  0.19277962\n",
      "  -0.35312266 -0.27019413]]\n",
      "weight_2 [[ 3.37947967]\n",
      " [ 0.69550429]\n",
      " [-2.89729689]\n",
      " [ 0.8250836 ]\n",
      " [-0.67192589]\n",
      " [ 0.48861689]\n",
      " [ 2.93206718]\n",
      " [ 0.10443291]\n",
      " [ 3.28590298]\n",
      " [ 1.08403441]\n",
      " [-1.1567535 ]\n",
      " [ 1.25764312]\n",
      " [ 2.01347533]\n",
      " [ 1.81762513]\n",
      " [-4.83373106]\n",
      " [-0.39233396]\n",
      " [ 2.13028952]\n",
      " [ 1.19801783]\n",
      " [-5.76180872]\n",
      " [ 1.47735417]\n",
      " [ 2.78210331]\n",
      " [ 1.57455136]\n",
      " [ 0.9495855 ]\n",
      " [-3.00227315]\n",
      " [-0.62055552]\n",
      " [-3.85978441]\n",
      " [-1.37326902]\n",
      " [-2.19254496]\n",
      " [ 1.24789397]\n",
      " [ 0.52616952]\n",
      " [ 0.92012025]\n",
      " [ 1.12857349]]\n",
      "\the current alpha value =  5\n",
      "Error =  0.49643992250078794\n",
      "Error =  0.0031288111022108236\n",
      "Error =  0.002148874613183779\n",
      "Error =  0.0017283934796573199\n",
      "Error =  0.0014820066652157572\n",
      "Error =  0.0013158061206984056\n",
      "weight_1 [[-4.80236027 -0.18537579 -1.49303547 -0.71406001 -1.55326439 -2.11819255\n",
      "  -0.63563205 -0.64648604 -4.86657265 -0.77163472 -1.65501673 -0.52256476\n",
      "  -0.74976116  2.23455819 -4.11774337 -0.14432112 -0.47663236  0.6530392\n",
      "  -5.46603418 -2.58938534  3.39215607  0.62521077 -0.89226574  0.88679935\n",
      "   0.04098306  3.68761411 -1.62745007 -1.86657329 -0.47997531  0.30723018\n",
      "  -1.97365923 -0.40493218]\n",
      " [ 3.73838162 -0.72979611  0.11832453 -0.73205586 -0.01889221  0.99255762\n",
      "  -1.56165124  0.0244707   3.77984956 -0.35406269 -1.64905551 -0.12535096\n",
      "  -1.25296211 -3.21800225  5.43288743 -1.10449022 -1.19633214 -1.91412231\n",
      "  -5.41187877  1.59863465 -4.56101851 -1.80418294 -0.26819111 -2.34618887\n",
      "  -0.72675004 -2.24686079 -1.430382    0.31498954 -0.94267607 -1.19878925\n",
      "   0.92585369 -0.56729456]\n",
      " [-1.93231256 -1.13748276 -0.71708081 -0.83455598 -0.54101604 -0.90119131\n",
      "   0.96050532 -1.50232755 -1.9426502  -0.90068833 -0.9364313  -1.51479171\n",
      "   0.19487188 -1.28153552  1.98513328 -0.86396809 -0.07537106 -0.648321\n",
      "   1.96362817 -1.12160628 -1.69676013 -0.6970337  -1.00501965 -0.45370285\n",
      "  -1.20791143  1.10392111 -1.15074318 -0.45961257 -0.71719018 -1.08101041\n",
      "  -0.98079982 -1.22561504]]\n",
      "weight_2 [[ 5.54139972]\n",
      " [ 0.37757636]\n",
      " [ 0.51600396]\n",
      " [ 0.25261931]\n",
      " [ 0.54703704]\n",
      " [ 1.48442099]\n",
      " [ 1.22051528]\n",
      " [ 0.19892504]\n",
      " [ 5.64582149]\n",
      " [ 0.35821797]\n",
      " [-1.26120935]\n",
      " [ 0.4388694 ]\n",
      " [ 0.5674872 ]\n",
      " [ 3.14803362]\n",
      " [-6.93290669]\n",
      " [ 0.371938  ]\n",
      " [ 0.70572059]\n",
      " [ 1.34868133]\n",
      " [-7.55694824]\n",
      " [ 2.18658326]\n",
      " [ 5.15934722]\n",
      " [ 1.29903955]\n",
      " [ 0.44274916]\n",
      " [ 1.43068738]\n",
      " [ 0.194902  ]\n",
      " [-3.42934229]\n",
      " [-1.21028953]\n",
      " [ 0.82998543]\n",
      " [ 0.44454544]\n",
      " [ 0.73273206]\n",
      " [ 1.39265634]\n",
      " [ 0.50959558]]\n",
      "\the current alpha value =  10\n",
      "Error =  0.49643992250078794\n",
      "Error =  0.002254538839644365\n",
      "Error =  0.0015372348629016657\n",
      "Error =  0.00123439543710358\n",
      "Error =  0.0010580718173873289\n",
      "Error =  0.0009395364918713383\n",
      "weight_1 [[-5.12981347 -0.39940291 -1.45711585 -1.01137359 -1.54713647 -2.27846015\n",
      "  -1.37910066  0.46489941 -5.51547069 -0.86958432 -1.70689212 -0.37598016\n",
      "  -1.63780113  2.34243791 -1.74765111 -0.66823165 -1.03655024 -0.04610745\n",
      "  -6.08389435 -2.14774122  4.27269283  2.31314256 -0.98345643 -0.02944815\n",
      "   3.23010338 -0.02498876 -1.44045683 -1.7178718  -0.94605825 -0.20835705\n",
      "  -1.79061185 -0.66237064]\n",
      " [ 3.81287314 -0.61229624 -0.81693177 -0.97346748 -0.73861315  0.76514381\n",
      "  -1.70535246  0.77095122  4.12872217 -0.57839343 -1.66805299 -0.11924695\n",
      "  -1.72569726 -3.53437928  0.06442295 -1.05719275 -1.32941766 -1.76509924\n",
      "  -6.02804247  0.73419584 -5.8015089  -3.77589313 -0.6089705  -1.96058889\n",
      "   3.27757319 -1.13108479 -1.23530421 -0.60259187 -1.11742832 -1.07248086\n",
      "   0.1893308  -0.70733363]\n",
      " [-2.02876428 -1.52714397 -1.2242008  -1.27004294 -1.15868887 -1.46223206\n",
      "  -0.74093515 -1.14475499 -2.14976064 -1.38826213 -1.01093371 -1.80202846\n",
      "  -0.71723801 -1.50885168 -1.42286911 -1.35055683 -1.04481628 -1.35325712\n",
      "   2.45541265 -1.6185515  -2.17486983 -1.36108395 -1.45263127 -1.16282022\n",
      "  -4.71861353 -1.5519827  -1.36404514 -1.15270615 -1.24094461 -1.63539506\n",
      "  -1.59283823 -1.63735076]]\n",
      "weight_2 [[ 5.19459456]\n",
      " [-0.52270727]\n",
      " [-0.5548398 ]\n",
      " [-0.52261533]\n",
      " [-0.41057647]\n",
      " [ 0.97955107]\n",
      " [-0.75008047]\n",
      " [-1.49643775]\n",
      " [ 5.85298225]\n",
      " [-0.48835558]\n",
      " [-1.44345191]\n",
      " [-0.56961184]\n",
      " [-1.03399794]\n",
      " [ 2.85558142]\n",
      " [ 0.21927148]\n",
      " [-0.43886377]\n",
      " [-0.46171907]\n",
      " [ 0.35822308]\n",
      " [-8.69592953]\n",
      " [ 0.93791255]\n",
      " [ 6.48550861]\n",
      " [ 3.01228139]\n",
      " [-0.36622479]\n",
      " [ 0.38738959]\n",
      " [-7.87413205]\n",
      " [-0.1405295 ]\n",
      " [-1.14608067]\n",
      " [-0.26314546]\n",
      " [-0.42787726]\n",
      " [-0.13914043]\n",
      " [ 0.41454431]\n",
      " [-0.2751824 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "alphaValues = [0.001, 0.01, 0.1, 5, 10]\n",
    "\n",
    "hiddenSize =32\n",
    "\n",
    "\n",
    "# Defining a sigmoid function\n",
    "def sigmoid(x):\n",
    "    output = 1 / (1 + np.exp(-x))\n",
    "    return output\n",
    "\n",
    "\n",
    "# derivative of sigmoid function\n",
    "def sigmoidDerivativeFunction(output):\n",
    "    output = output * (1 - output)\n",
    "    return output\n",
    "\n",
    "\n",
    "# Some values to construct the nural net work\n",
    "# Later we will be using the actual data from the iris data set\n",
    "\n",
    "X = np.array([[0, 0, 1],\n",
    "              [0, 1, 1],\n",
    "              [1, 0, 1],\n",
    "              [1, 1, 1]])\n",
    "\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])\n",
    "\n",
    "for alpha in alphaValues:\n",
    "    print(\"\\the current alpha value = \", alpha)\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # initializing Random weights\n",
    "\n",
    "    weight_1 = 2 * np.random.random((3, hiddenSize)) - 1\n",
    "    weight_2 = 2 * np.random.random((hiddenSize, 1)) - 1\n",
    "\n",
    "    # checking the weights to see how the gradiants are changing\n",
    "\n",
    "    weight_1_dirCount = np.zeros_like(weight_1)\n",
    "    weight_2_dirCount = np.zeros_like(weight_2)\n",
    "\n",
    "    prev_weight_1_update = np.zeros_like(weight_1)\n",
    "    prev_weight_2_update = np.zeros_like(weight_2  )\n",
    "\n",
    "    for j in range(60000):\n",
    "        # Forward propogation from one layer to another i.e between layers 0 , 1, 2\n",
    "        # layer_0 = X\n",
    "        # layer_1 = sigmoid(np.dot(layer_0,weight_1))   #Here we are multiplying   ThetaTranspose* X\n",
    "        # print(type(layer_1))\n",
    "        # layer_2 = sigmoid(np.dot(layer_1,weight_2)) # the same thing with respoect to the second layer .. ie thetaTranspose*X\n",
    "\n",
    "        layer_0 = X\n",
    "        layer_1 = sigmoid(np.dot(layer_0, weight_1))\n",
    "        layer_2 = sigmoid(np.dot(layer_1, weight_2))\n",
    "        # Caliculating the error value\n",
    "\n",
    "        ForwardPropError = y - layer_2\n",
    "\n",
    "        if (j % 10000) == 0:\n",
    "            print(\"Error = \", np.mean(np.abs(ForwardPropError)))\n",
    "\n",
    "        ##Back propogation\n",
    "        layer2_Sigma = ForwardPropError * sigmoidDerivativeFunction(layer_2)\n",
    "\n",
    "        layer1_Error = layer2_Sigma.dot(weight_2.T)\n",
    "\n",
    "        layer_1Sigma = layer1_Error * sigmoidDerivativeFunction(layer_1)\n",
    "\n",
    "        # We are suggesting values .. i.e how much of it is wrong in each layer\n",
    "        # baically updating the weights withs respective to values and the errors observed\n",
    "        weight_2_Update = (layer_1.T.dot(layer2_Sigma))\n",
    "        weight_1_Update = (layer_0.T.dot(layer_1Sigma))\n",
    "\n",
    "        # We are checking what direction the gradient is moving\n",
    "        if (j > 0):\n",
    "            weight_1_dirCount += np.abs(((weight_1_Update > 0) + 0) -\n",
    "\n",
    "                                        ((prev_weight_1_update > 0) + 0))\n",
    "            weight_2_dirCount += np.abs(((weight_2_Update > 0) + 0) -\n",
    "\n",
    "                                        ((prev_weight_2_update > 0) + 0))\n",
    "        weight_1 += alpha * weight_1_Update\n",
    "        weight_2 += alpha * weight_2_Update\n",
    "\n",
    "        prev_weight_1_update = weight_1_Update\n",
    "        prev_weight_2_update = weight_2_Update\n",
    "\n",
    "    print(\"weight_1\", weight_1)\n",
    "    print(\"weight_2\", weight_2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\the current alpha value =  0.001\n",
      "Error =  0.49643992250078794\n",
      "Error =  0.49104946812904954\n",
      "Error =  0.4849763070274596\n",
      "Error =  0.4778306787926556\n",
      "Error =  0.4690384653902826\n",
      "Error =  0.458029258565275\n",
      "weight_1 [[-0.66945036  0.44057532 -0.91759208 -0.36525547 -0.76011568 -0.82926418\n",
      "  -0.61094522 -0.22947974 -0.67917735  0.15292538 -0.35220283  0.3339454\n",
      "  -0.59142231  0.67756675 -1.11442476  0.54733702 -0.31555027  0.11348483\n",
      "  -1.42577089 -0.75857317  0.67526556  0.75670996 -0.38885609  0.94740732\n",
      "   0.79895388  1.35107823 -0.82206512 -0.99660592 -0.40374837  0.75100038\n",
      "  -0.85239719 -0.11992929]\n",
      " [ 0.9583388   0.07763217  0.83646247 -0.34174625  0.57380012  0.64850887\n",
      "  -0.90837847  0.49541604  0.96767225  0.50496084 -0.51623496  0.55803271\n",
      "  -0.78484996 -0.25896594  1.37458204 -0.45776431 -0.51938006 -0.78121801\n",
      "  -1.54926221  0.42897347 -0.82710662 -0.14644147  0.00949155 -1.04761586\n",
      "  -0.17898997 -0.88967639 -0.25319071  0.77334008 -0.59686327 -0.16546404\n",
      "   0.40869142 -0.14650144]\n",
      " [-1.04683863  0.07963318  0.66801365  0.06652616  0.93839423  0.14678197\n",
      "   1.20313646 -0.70995186 -0.92113825  0.62874623 -0.29573615 -0.52831034\n",
      "   1.04482412 -0.37911984  0.85830354  0.53155125  0.86724329  0.23148292\n",
      "   0.06723081 -0.38942519 -0.59398695  0.76839252 -0.12919343  1.10968593\n",
      "   0.30301338  0.672497   -0.80031271  1.02153667  0.06853563  0.15447002\n",
      "  -0.22232653 -0.49502833]]\n",
      "weight_2 [[ 0.98938611]\n",
      " [ 0.18866442]\n",
      " [-1.05810607]\n",
      " [ 0.28955579]\n",
      " [-0.45175944]\n",
      " [ 0.07506167]\n",
      " [ 1.03264194]\n",
      " [-0.20464657]\n",
      " [ 0.98148582]\n",
      " [ 0.32310523]\n",
      " [-0.94113854]\n",
      " [ 0.82451502]\n",
      " [ 0.62413972]\n",
      " [ 1.02508842]\n",
      " [-1.09453409]\n",
      " [-0.72941822]\n",
      " [ 1.01787791]\n",
      " [ 0.49938368]\n",
      " [-1.34636059]\n",
      " [ 0.66306791]\n",
      " [ 0.74100847]\n",
      " [ 0.74366985]\n",
      " [ 0.48941783]\n",
      " [-0.99536183]\n",
      " [-0.93638148]\n",
      " [-1.22252427]\n",
      " [-0.90194915]\n",
      " [-0.70648747]\n",
      " [ 0.66498038]\n",
      " [ 0.06759568]\n",
      " [ 0.27350793]\n",
      " [ 0.7272871 ]]\n",
      "\the current alpha value =  0.01\n",
      "Error =  0.49643992250078794\n",
      "Error =  0.35637906164802124\n",
      "Error =  0.14693984546476\n",
      "Error =  0.08801561274158767\n",
      "Error =  0.06514781927504912\n",
      "Error =  0.052965808702569714\n",
      "weight_1 [[-2.43832073e+00  4.60386826e-01 -2.01731865e+00 -3.04193839e-01\n",
      "  -1.01760482e+00 -8.95344104e-01 -1.23100667e+00 -1.93076595e-01\n",
      "  -2.39779504e+00  4.59640619e-01 -1.04026630e+00  5.98257611e-01\n",
      "  -8.59036527e-01  7.90732877e-01 -3.06569583e+00  8.68107104e-01\n",
      "  -6.68450586e-01  1.42837490e-01 -3.80337709e+00 -1.28282347e+00\n",
      "   1.55574451e+00  9.04139533e-01 -4.02103990e-01  2.67679073e+00\n",
      "   1.08333513e+00  3.27051548e+00 -1.32275851e+00 -1.81496615e+00\n",
      "  -2.18276320e-01  7.20213604e-01 -1.07229877e+00 -3.24165455e-02]\n",
      " [ 2.08982983e+00  1.10629500e-01  2.51694461e+00 -3.41784146e-01\n",
      "   1.08244113e+00  5.65415920e-01 -1.42742238e+00  4.96484687e-01\n",
      "   2.01526872e+00  6.19069164e-01 -1.04442466e+00  6.73514678e-01\n",
      "  -1.05337109e+00 -1.03501971e+00  3.67163223e+00 -5.93331646e-01\n",
      "  -8.72924756e-01 -9.44060464e-01 -3.75881013e+00  7.43269593e-01\n",
      "  -2.09280104e+00  4.96432241e-01 -2.48286354e-04 -2.29546885e+00\n",
      "  -4.79084417e-01 -2.60408572e+00 -1.05996647e+00  2.08444051e+00\n",
      "  -5.74543279e-01 -1.27021185e-01  5.04031979e-01 -2.15597595e-01]\n",
      " [-1.42854714e+00  1.68655957e-01  1.25671641e+00  2.15395596e-01\n",
      "   1.01289945e+00  6.99349106e-02  2.27506957e+00 -7.11085303e-01\n",
      "  -1.38035106e+00  7.65966915e-01 -5.75057588e-01 -6.78978559e-02\n",
      "   1.68491657e+00 -6.13440443e-01  1.67258663e+00  6.21424708e-01\n",
      "   1.41210554e+00  2.75368603e-01  1.11665203e+00 -6.04878998e-01\n",
      "  -1.02739053e+00  9.25097072e-01 -1.36575878e-02  1.49426849e+00\n",
      "   3.82695444e-01  1.49679862e+00 -8.27985163e-01  1.28620392e+00\n",
      "   3.81259070e-01  1.75392595e-01 -3.25076654e-01 -3.28670228e-01]]\n",
      "weight_2 [[ 2.66096509]\n",
      " [ 0.57910777]\n",
      " [-2.31624565]\n",
      " [ 0.69614999]\n",
      " [-0.61921698]\n",
      " [ 0.38370865]\n",
      " [ 2.41768602]\n",
      " [ 0.03915781]\n",
      " [ 2.59124913]\n",
      " [ 0.89678116]\n",
      " [-1.06112574]\n",
      " [ 1.11364609]\n",
      " [ 1.66710323]\n",
      " [ 1.58182007]\n",
      " [-3.85805142]\n",
      " [-0.4732592 ]\n",
      " [ 1.84452223]\n",
      " [ 1.04122519]\n",
      " [-4.77334992]\n",
      " [ 1.26988353]\n",
      " [ 2.16733497]\n",
      " [ 1.34523229]\n",
      " [ 0.84256179]\n",
      " [-2.42618942]\n",
      " [-0.69069769]\n",
      " [-3.12866285]\n",
      " [-1.24090828]\n",
      " [-1.74872637]\n",
      " [ 1.09920224]\n",
      " [ 0.41676158]\n",
      " [ 0.77927967]\n",
      " [ 1.03150226]]\n",
      "\the current alpha value =  0.1\n",
      "Error =  0.49643992250078794\n",
      "Error =  0.030540490838555055\n",
      "Error =  0.01906387253341843\n",
      "Error =  0.014764390729581685\n",
      "Error =  0.012389242990471297\n",
      "Error =  0.010842166973777436\n",
      "weight_1 [[-3.00322215  0.46988894 -2.44991785 -0.29169761 -1.09401703 -0.9246919\n",
      "  -1.49570085 -0.19780982 -2.94732077  0.56920477 -1.20054236  0.7391777\n",
      "  -0.99690935  0.94093814 -3.62281609  0.91569534 -0.7988119   0.15271547\n",
      "  -4.33228259 -1.47490619  1.9780427   1.01855886 -0.40316011  3.16640116\n",
      "   1.14341525  3.78831657 -1.46232124 -2.14327959 -0.20790141  0.7105365\n",
      "  -1.15280043 -0.01020385]\n",
      " [ 2.55896632  0.12301871  3.01334738 -0.35452918  1.20612737  0.53836365\n",
      "  -1.67610985  0.49504917  2.47727206  0.68434391 -1.18690082  0.7721176\n",
      "  -1.1905724  -1.31975184  4.26537029 -0.61613413 -1.0057858  -0.99941692\n",
      "  -4.27416525  0.8811371  -2.58080845  0.67543441 -0.01435424 -2.70689673\n",
      "  -0.52270831 -3.10389429 -1.22829798  2.50171098 -0.59908413 -0.11270296\n",
      "   0.54708441 -0.24737497]\n",
      " [-1.56858975  0.20874264  1.40901944  0.27284564  1.02544792  0.04778983\n",
      "   2.66934814 -0.70912552 -1.52307164  0.81772844 -0.59750004  0.07534279\n",
      "   1.9235337  -0.69438737  1.9086195   0.62983806  1.63433941  0.30199459\n",
      "   1.43660642 -0.6758208  -1.18195766  0.96226455  0.034289    1.62411911\n",
      "   0.39837764  1.7065     -0.78857418  1.37036702  0.47229136  0.19277962\n",
      "  -0.35312266 -0.27019413]]\n",
      "weight_2 [[ 3.37947967]\n",
      " [ 0.69550429]\n",
      " [-2.89729689]\n",
      " [ 0.8250836 ]\n",
      " [-0.67192589]\n",
      " [ 0.48861689]\n",
      " [ 2.93206718]\n",
      " [ 0.10443291]\n",
      " [ 3.28590298]\n",
      " [ 1.08403441]\n",
      " [-1.1567535 ]\n",
      " [ 1.25764312]\n",
      " [ 2.01347533]\n",
      " [ 1.81762513]\n",
      " [-4.83373106]\n",
      " [-0.39233396]\n",
      " [ 2.13028952]\n",
      " [ 1.19801783]\n",
      " [-5.76180872]\n",
      " [ 1.47735417]\n",
      " [ 2.78210331]\n",
      " [ 1.57455136]\n",
      " [ 0.9495855 ]\n",
      " [-3.00227315]\n",
      " [-0.62055552]\n",
      " [-3.85978441]\n",
      " [-1.37326902]\n",
      " [-2.19254496]\n",
      " [ 1.24789397]\n",
      " [ 0.52616952]\n",
      " [ 0.92012025]\n",
      " [ 1.12857349]]\n",
      "\the current alpha value =  5\n",
      "Error =  0.49643992250078794\n",
      "Error =  0.0031288111022108236\n",
      "Error =  0.002148874613183779\n",
      "Error =  0.0017283934796573199\n",
      "Error =  0.0014820066652157572\n",
      "Error =  0.0013158061206984056\n",
      "weight_1 [[-4.80236027 -0.18537579 -1.49303547 -0.71406001 -1.55326439 -2.11819255\n",
      "  -0.63563205 -0.64648604 -4.86657265 -0.77163472 -1.65501673 -0.52256476\n",
      "  -0.74976116  2.23455819 -4.11774337 -0.14432112 -0.47663236  0.6530392\n",
      "  -5.46603418 -2.58938534  3.39215607  0.62521077 -0.89226574  0.88679935\n",
      "   0.04098306  3.68761411 -1.62745007 -1.86657329 -0.47997531  0.30723018\n",
      "  -1.97365923 -0.40493218]\n",
      " [ 3.73838162 -0.72979611  0.11832453 -0.73205586 -0.01889221  0.99255762\n",
      "  -1.56165124  0.0244707   3.77984956 -0.35406269 -1.64905551 -0.12535096\n",
      "  -1.25296211 -3.21800225  5.43288743 -1.10449022 -1.19633214 -1.91412231\n",
      "  -5.41187877  1.59863465 -4.56101851 -1.80418294 -0.26819111 -2.34618887\n",
      "  -0.72675004 -2.24686079 -1.430382    0.31498954 -0.94267607 -1.19878925\n",
      "   0.92585369 -0.56729456]\n",
      " [-1.93231256 -1.13748276 -0.71708081 -0.83455598 -0.54101604 -0.90119131\n",
      "   0.96050532 -1.50232755 -1.9426502  -0.90068833 -0.9364313  -1.51479171\n",
      "   0.19487188 -1.28153552  1.98513328 -0.86396809 -0.07537106 -0.648321\n",
      "   1.96362817 -1.12160628 -1.69676013 -0.6970337  -1.00501965 -0.45370285\n",
      "  -1.20791143  1.10392111 -1.15074318 -0.45961257 -0.71719018 -1.08101041\n",
      "  -0.98079982 -1.22561504]]\n",
      "weight_2 [[ 5.54139972]\n",
      " [ 0.37757636]\n",
      " [ 0.51600396]\n",
      " [ 0.25261931]\n",
      " [ 0.54703704]\n",
      " [ 1.48442099]\n",
      " [ 1.22051528]\n",
      " [ 0.19892504]\n",
      " [ 5.64582149]\n",
      " [ 0.35821797]\n",
      " [-1.26120935]\n",
      " [ 0.4388694 ]\n",
      " [ 0.5674872 ]\n",
      " [ 3.14803362]\n",
      " [-6.93290669]\n",
      " [ 0.371938  ]\n",
      " [ 0.70572059]\n",
      " [ 1.34868133]\n",
      " [-7.55694824]\n",
      " [ 2.18658326]\n",
      " [ 5.15934722]\n",
      " [ 1.29903955]\n",
      " [ 0.44274916]\n",
      " [ 1.43068738]\n",
      " [ 0.194902  ]\n",
      " [-3.42934229]\n",
      " [-1.21028953]\n",
      " [ 0.82998543]\n",
      " [ 0.44454544]\n",
      " [ 0.73273206]\n",
      " [ 1.39265634]\n",
      " [ 0.50959558]]\n",
      "\the current alpha value =  10\n",
      "Error =  0.49643992250078794\n",
      "Error =  0.002254538839644365\n",
      "Error =  0.0015372348629016657\n",
      "Error =  0.00123439543710358\n",
      "Error =  0.0010580718173873289\n",
      "Error =  0.0009395364918713383\n",
      "weight_1 [[-5.12981347 -0.39940291 -1.45711585 -1.01137359 -1.54713647 -2.27846015\n",
      "  -1.37910066  0.46489941 -5.51547069 -0.86958432 -1.70689212 -0.37598016\n",
      "  -1.63780113  2.34243791 -1.74765111 -0.66823165 -1.03655024 -0.04610745\n",
      "  -6.08389435 -2.14774122  4.27269283  2.31314256 -0.98345643 -0.02944815\n",
      "   3.23010338 -0.02498876 -1.44045683 -1.7178718  -0.94605825 -0.20835705\n",
      "  -1.79061185 -0.66237064]\n",
      " [ 3.81287314 -0.61229624 -0.81693177 -0.97346748 -0.73861315  0.76514381\n",
      "  -1.70535246  0.77095122  4.12872217 -0.57839343 -1.66805299 -0.11924695\n",
      "  -1.72569726 -3.53437928  0.06442295 -1.05719275 -1.32941766 -1.76509924\n",
      "  -6.02804247  0.73419584 -5.8015089  -3.77589313 -0.6089705  -1.96058889\n",
      "   3.27757319 -1.13108479 -1.23530421 -0.60259187 -1.11742832 -1.07248086\n",
      "   0.1893308  -0.70733363]\n",
      " [-2.02876428 -1.52714397 -1.2242008  -1.27004294 -1.15868887 -1.46223206\n",
      "  -0.74093515 -1.14475499 -2.14976064 -1.38826213 -1.01093371 -1.80202846\n",
      "  -0.71723801 -1.50885168 -1.42286911 -1.35055683 -1.04481628 -1.35325712\n",
      "   2.45541265 -1.6185515  -2.17486983 -1.36108395 -1.45263127 -1.16282022\n",
      "  -4.71861353 -1.5519827  -1.36404514 -1.15270615 -1.24094461 -1.63539506\n",
      "  -1.59283823 -1.63735076]]\n",
      "weight_2 [[ 5.19459456]\n",
      " [-0.52270727]\n",
      " [-0.5548398 ]\n",
      " [-0.52261533]\n",
      " [-0.41057647]\n",
      " [ 0.97955107]\n",
      " [-0.75008047]\n",
      " [-1.49643775]\n",
      " [ 5.85298225]\n",
      " [-0.48835558]\n",
      " [-1.44345191]\n",
      " [-0.56961184]\n",
      " [-1.03399794]\n",
      " [ 2.85558142]\n",
      " [ 0.21927148]\n",
      " [-0.43886377]\n",
      " [-0.46171907]\n",
      " [ 0.35822308]\n",
      " [-8.69592953]\n",
      " [ 0.93791255]\n",
      " [ 6.48550861]\n",
      " [ 3.01228139]\n",
      " [-0.36622479]\n",
      " [ 0.38738959]\n",
      " [-7.87413205]\n",
      " [-0.1405295 ]\n",
      " [-1.14608067]\n",
      " [-0.26314546]\n",
      " [-0.42787726]\n",
      " [-0.13914043]\n",
      " [ 0.41454431]\n",
      " [-0.2751824 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "alphaValues = [0.001, 0.01, 0.1, 5, 10]\n",
    "hiddenSize =32\n",
    "# Defining a sigmoid function\n",
    "def sigmoid(x):\n",
    "    output = 1 / (1 + np.exp(-x))\n",
    "    return output\n",
    "\n",
    "\n",
    "# derivative of sigmoid function\n",
    "def sigmoidDerivativeFunction(output):\n",
    "    output = output * (1 - output)\n",
    "    return output\n",
    "\n",
    "def forwardProp(X,weight_1,weight_2):\n",
    "    ##Forward Propogation\n",
    "    layer_0 = X\n",
    "    layer_1 = sigmoid(np.dot(layer_0, weight_1))\n",
    "    layer_2 = sigmoid(np.dot(layer_1, weight_2))\n",
    "    return layer_0,layer_1,layer_2\n",
    "\n",
    "def backwardProp(weight_1,weight_2,layer_1,layer_2,alpha,ForwardPropError):\n",
    "    #Caliculating the error value\n",
    "    layer_2_Sigma = ForwardPropError * sigmoidDerivativeFunction(layer_2)\n",
    "    layer_1_Error = layer_2_Sigma.dot(weight_2.T)\n",
    "    layer_1_Sigma = layer_1_Error * sigmoidDerivativeFunction(layer_1)\n",
    "    # We are suggesting values .. i.e how much of it is wrong in each layer\n",
    "    # baically updating the weights withs respective to values and the errors observed\n",
    "    weight_1_Update = (layer_0.T.dot(layer_1_Sigma))\n",
    "    weight_2_Update = (layer_1.T.dot(layer_2_Sigma))\n",
    "    # We are checking what direction the gradient is moving\n",
    "    weight_1 += alpha * weight_1_Update\n",
    "    weight_2 += alpha * weight_2_Update\n",
    "    return weight_1,weight_2\n",
    "# Some values to construct the nural net work\n",
    "# Later we will be using the actual data from the iris data set\n",
    "\n",
    "X = np.array([[0, 0, 1],\n",
    "              [0, 1, 1],\n",
    "              [1, 0, 1],\n",
    "              [1, 1, 1]])\n",
    "\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])\n",
    "\n",
    "for alpha in alphaValues:\n",
    "    print(\"\\the current alpha value = \", alpha)\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # initializing Random weights\n",
    "\n",
    "    weight_1 = 2 * np.random.random((3, hiddenSize)) - 1\n",
    "    weight_2 = 2 * np.random.random((hiddenSize, 1)) - 1\n",
    "\n",
    "    # checking the weights to see how the gradiants are changing\n",
    "    for j in range(60000):\n",
    "        # Forward propogation from one layer to another i.e between layers 0 , 1, 2\n",
    "        # Caliculating the error value\n",
    "        layer_0,layer_1,layer_2 = forwardProp(X,weight_1,weight_2)\n",
    "        ForwardPropError = y - layer_2\n",
    "        if (j % 10000) == 0:\n",
    "            print(\"Error = \", np.mean(np.abs(ForwardPropError)))\n",
    "        weight_1,weight_2 = backwardProp(weight_1,weight_2,layer_1,layer_2,alpha,ForwardPropError)\n",
    "    print(\"weight_1\", weight_1)\n",
    "    print(\"weight_2\", weight_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
